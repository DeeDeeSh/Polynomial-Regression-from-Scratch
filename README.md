# 📘 Polynomial Regression from Scratch

This project demonstrates how to implement **polynomial regression (quadratic)** from scratch using only **Python and NumPy** — no machine learning libraries like scikit-learn are used.

---

## 🔍 What’s Inside

- ✅ Synthetic data generation
- ✅ Manual implementation of the **cost function**
- ✅ **Gradient descent** algorithm using partial derivatives
- ✅ Parameter tuning without libraries
- ✅ Multiple **visualizations**:
  - Dependancy of cost with weight
  - True vs predicted values curve
 
---

## 💡 Why This Project?

This is a learning-focused project to:
- Strengthen understanding of core ML concepts
- Practice implementing algorithms manually
- Visualize model performance and optimization process

---

## 🛠 How to Run

1. Clone or download the repository
2. Open the notebook `polynomial_Regression_from_scratch.ipynb` in Jupyter, Kaggle, or Colab
3. Run all cells to see training, gradient updates, and plots

---

## 📊 Example Output

- Polynomial regression learns a quadratic relationship:
  Y = w1 * X + w2 * X² + b
  - Trained weights get close to true values using gradient descent

---

## 📎 Dependencies

- NumPy
- Matplotlib

---

## 🚀 Sample Results

| Plot | Description |
|------|-------------|
| ✅ Cost vs Iteration | Shows cost reducing over time |
| ✅ Predictions | Before vs after gradient descent |

---

## 🤝 Contributions & Ideas

Pull requests and suggestions are welcome! Feel free to fork the repo and extend it with:
- More polynomial degrees
- Live animation of gradient descent

---

## 📌 Author

**Devansh Sharma** — B.Tech ECE Student | Learning AI/ML
📫 Connect: [www.linkedin.com/in/devansh-sharma-02942a318]  

---
