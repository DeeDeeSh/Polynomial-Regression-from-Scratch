# ğŸ“˜ Polynomial Regression from Scratch

This project demonstrates how to implement **polynomial regression (quadratic)** from scratch using only **Python and NumPy** â€” no machine learning libraries like scikit-learn are used.

---

## ğŸ” Whatâ€™s Inside

- âœ… Synthetic data generation
- âœ… Manual implementation of the **cost function**
- âœ… **Gradient descent** algorithm using partial derivatives
- âœ… Parameter tuning without libraries
- âœ… Multiple **visualizations**:
  - Dependancy of cost with weight
  - True vs predicted values curve
 
---

## ğŸ’¡ Why This Project?

This is a learning-focused project to:
- Strengthen understanding of core ML concepts
- Practice implementing algorithms manually
- Visualize model performance and optimization process

---

## ğŸ›  How to Run

1. Clone or download the repository
2. Open the notebook `polynomial_Regression_from_scratch.ipynb` in Jupyter, Kaggle, or Colab
3. Run all cells to see training, gradient updates, and plots

---

## ğŸ“Š Example Output

- Polynomial regression learns a quadratic relationship:
  Y = w1 * X + w2 * XÂ² + b
  - Trained weights get close to true values using gradient descent

---

## ğŸ“ Dependencies

- NumPy
- Matplotlib

---

## ğŸš€ Sample Results

| Plot | Description |
|------|-------------|
| âœ… Cost vs Iteration | Shows cost reducing over time |
| âœ… Predictions | Before vs after gradient descent |

---

## ğŸ¤ Contributions & Ideas

Pull requests and suggestions are welcome! Feel free to fork the repo and extend it with:
- More polynomial degrees
- Live animation of gradient descent

---

## ğŸ“Œ Author

**Devansh Sharma** â€” B.Tech ECE Student | Learning AI/ML
ğŸ“« Connect: [www.linkedin.com/in/devansh-sharma-02942a318]  

---
